{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyse_purchases_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## how to use\n",
        "\n",
        "1. Unzip and Install requirements\n",
        "```\n",
        "dask==2022.4.1\n",
        "numpy==1.22.3\n",
        "pandas==1.4.2\n",
        "notebook==6.4.2\n",
        "```\n",
        "\n",
        "\n",
        "2. [option 1] Start Jupyter Notebook in the same folder\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "jupyter notebook\n",
        "```\n",
        "3. [option 2] run python file\n",
        "```bash\n",
        "python analyse_purchases.py\n",
        "```\n",
        "\n",
        "### Quick-Start\n",
        "\n",
        "- populate `FILEPATH` with the relative or absolute location of csv and run the Cells\n",
        "\n",
        "### Configuration of parameters\n",
        "\n",
        "    FILTER_THRESHOLD: Populate this variable to filter relavant observations, defaulted to 2\n",
        "    SEGMENT_CATEGORIES: Populate this list with the column headers of the csv file on which you want to create segments(refer to functionalities in next section for more details)\n",
        "    IGNORE_USER_TYPES: Populate this list with the users you want to exclude from your analysis(refer to functionalities in next section for more details)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Functionalities and Design Choices\n",
        "- segement columns: Populate SEGMENT_CATEGORIES with the column names on which you want the segments to be created.\n",
        "  - for example if SEGMENT_CATEGORIES = [\"country\"], then you will see observations like \n",
        "    - users from canada\n",
        "    - users from korea\n",
        "  - for example if  SEGMENT_CATEGORIES = [\"country\"], then you would see observation like \n",
        "    - users who are from canada\n",
        "    - users who are from canada and are VIP\n",
        "    - users who are from canada and are not VIP\n",
        "- Segments are grouped, they will be ordered by the sequence of SEGMENT_CATEGORIES\n",
        "  - for example if it is set to  [\"country\", \"is_vip\"] then it will be first grouped by country and then VIP status\n",
        "    - For example all segments belonging to CANADA will occur together\n",
        "      - users who are from canada\n",
        "      - users who are from canada and are VIP\n",
        "      - users who are from canada and are not VIP\n",
        "- Ignoring Users: a function called user_type add a column called `user_type` which categorizes the users into 4 categories: [\"regular_customer\",\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]. A variable IGNORE_USER_TYPES is populated and all user types in this list would be excluded from the analysis.\n",
        "- `getDf()` Have created this function so that if in future if we need to read from some other source such as mysql, we can just edit this function\n",
        "- `metric` have tried to maintain this variable whenever possible so that in future in we have a new metric we can easily add more conditions\n",
        "\n",
        "## Assumptions\n",
        "- percentage calculation logic: The percentage is being calculated by comparing to yesterday\n",
        "$$\n",
        " PercentChange = \\frac{PurchaseToday - PurchaseYesterday}{PurchaseYesterday}\\times 100\n",
        "  $$\n",
        "- Ignore user_types logic: Ignoring users\n",
        "- User_ids are not repeated: if repeated we can first groupBy-Sum on user_id,country and is_vip and then start the whole process\n",
        "\n",
        "\n",
        "\n",
        "## Future steps\n",
        "\n",
        "- Reusability: add functions so that if business logic changes, the amount of changes we need to do is minimal\n",
        "- Parallelization: Very similar to apache spark we can use dask in an asynchronus manner, so that it computes only when results are needed. The current parallelization is very naive"
      ],
      "metadata": {
        "id": "VzfjckasVSxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install 'fsspec>=0.3.3'\n",
        "# !pip install dask"
      ],
      "metadata": {
        "id": "aVLpkMkuKdO6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CA5uf03iJJh_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd  # Dask Multiprocessing\n",
        "from itertools import combinations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reader and Filter Module"
      ],
      "metadata": {
        "id": "mlzx9UJ6JhAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def getDf(filename):\n",
        "    \"\"\"\n",
        "    function to return data frame from csv,\n",
        "    can be modified to read from mysql\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(filename)\n",
        "    return df\n",
        "\n",
        "\n",
        "def user_type(yesterday, today):\n",
        "    \"\"\"\n",
        "    function to find out the types of users\n",
        "    \"\"\"\n",
        "    if (yesterday == 0 and today == 0):\n",
        "        return \"non_paying\"\n",
        "    if (yesterday == 0 and today != 0):\n",
        "        return \"abstained_yesterday\"\n",
        "    if (yesterday != 0 and today == 0):\n",
        "        return \"abstained_today\"\n",
        "    if (yesterday != 0 and today != 0):\n",
        "        return \"regular_user\"\n",
        "\n",
        "\n",
        "def amount_change(yesterday, today):\n",
        "    return today - yesterday\n"
      ],
      "metadata": {
        "id": "tX2r4MY-Je_K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stats Generation and Analysis Module\n"
      ],
      "metadata": {
        "id": "0SQCsyApJzlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_name(row, columns):\n",
        "    values = [column + \":\" + str(row[column]) for column in columns]\n",
        "    return ','.join(values)\n",
        "\n",
        "\n",
        "def getCombinations(columns):\n",
        "    n = len(columns)\n",
        "    res = [list(com) for sub in range(n) for com in combinations(columns, sub + 1)]\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_analysis(df, metric, segment_columns, maintain_columns, numerator_column, denominator_column):\n",
        "    \"\"\"\n",
        "    Gets Segments on segment_columns and calculates stats(value and percentage) \n",
        "    on the given metric and returns an standard dataframe\n",
        "    \n",
        "    Arguments:\n",
        "    df: input data frame\n",
        "    metric: \"total\"/\"average\"\n",
        "    segment_columns: \"column header on which segments to be generated\"\n",
        "    maintain_column: list of columns to be maintained after group by\n",
        "    numerator_column: numerator column which has today's value\n",
        "    denominator_column: denominator column which has today's value\n",
        "    \"\"\"\n",
        "\n",
        "    # get all posible combinations of given segment categories\n",
        "    all_segments = getCombinations(segment_columns)\n",
        "    metric_column_denominator = denominator_column\n",
        "    metric_column_change_percentage = numerator_column + \"_percentage\"\n",
        "\n",
        "    combined_df = pd.DataFrame()\n",
        "    for segment in all_segments:\n",
        "        segment_df = df\n",
        "        #  get metric \n",
        "        if(metric == \"total\"):\n",
        "            segment_df = segment_df.groupby(segment)[\n",
        "                [numerator_column, metric_column_denominator] + maintain_columns].sum().reset_index()\n",
        "        elif(metric == \"average\"):\n",
        "            segment_df = segment_df.groupby(segment)[\n",
        "                [numerator_column, metric_column_denominator] + maintain_columns].mean().reset_index()\n",
        "\n",
        "        # get percentage\n",
        "        segment_df[metric_column_change_percentage] = segment_df.apply(\n",
        "            lambda x: x[numerator_column] * 100 / x[metric_column_denominator], axis=1)\n",
        "        segment_df[\"segment_name\"] = segment_df.apply(lambda x: segment_name(x, segment), axis=1)\n",
        "\n",
        "        # selecting columns to maintain standard format\n",
        "        segment_df = segment_df[\n",
        "            ['segment_name', numerator_column, metric_column_change_percentage] + maintain_columns]\n",
        "\n",
        "        combined_df = combined_df.append(segment_df)\n",
        "\n",
        "    # sorting by segment_name to group segments together\n",
        "    combined_df = combined_df.sort_values(by=['segment_name']).reset_index(drop=True)\n",
        "    return combined_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_overallStats(df, current_column,numerator_column, denominator_column,metric):\n",
        "    \"\"\"\n",
        "    Returns overall absolute change, overall absolute change percentage\n",
        "    and overall_purchase today for the given metric without segmenting\n",
        "    \"\"\"\n",
        "    if(metric == \"total\"):\n",
        "        overall_absolute_change = df[numerator_column].sum()\n",
        "        overall_purchase_yesterday = df[denominator_column].sum()\n",
        "        overall_purchase_today = df[current_column].sum()\n",
        "        overall_change_percentage = df[numerator_column].sum() / overall_purchase_yesterday * 100\n",
        "    elif(metric == \"average\"):\n",
        "        overall_absolute_change = df[numerator_column].mean()\n",
        "        overall_purchase_yesterday = df[denominator_column].mean()\n",
        "        overall_change_percentage = df[numerator_column].mean() / overall_purchase_yesterday * 100\n",
        "        overall_purchase_today = df[current_column].mean()\n",
        "    return overall_purchase_today,overall_absolute_change, overall_change_percentage\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UEiKx2RDJQGT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human Readable String generation module"
      ],
      "metadata": {
        "id": "VgyuLG5sKEM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bq-WkkS0J9Ac"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_category(key_value):\n",
        "    \"\"\"\n",
        "    returns human readable segments string given segement_name in specific format\n",
        "    example: \"Users who are from australia and are VIP\"\n",
        "    \"\"\"\n",
        "    pair = key_value.split(\":\")\n",
        "    c = \"\"\n",
        "    if(pair[0] == \"country\"):\n",
        "        c = \"are from \"+pair[1]\n",
        "    else:\n",
        "        if(pair[1] == \"False\"):\n",
        "            c = \"are not VIP\"\n",
        "        else:\n",
        "            c = \"are VIP\"\n",
        "    return c\n",
        "\n",
        "def get_stats_string(amount,percentage):\n",
        "    \"\"\"\n",
        "    returns human readable stats String given current amount and percentage\n",
        "    example: \"$2805633 (Down 212.58%  from yesterday)\"\n",
        "    \"\"\"\n",
        "    string = ': $%d' % amount\n",
        "    if(percentage >= 0):\n",
        "        string = string + \" (Up %.2f%%  from yesterday)\"%percentage\n",
        "    else:\n",
        "        string = string + \" (Down %.2f%%  from yesterday)\"%abs(percentage)\n",
        "    return string\n",
        "\n",
        "def humanReadableString(segment_name,current_amount,percentage_change):\n",
        "    \"\"\"\n",
        "    returns Human readble string using:\n",
        "    segment_name: segment's name in given format \"country:australia,is_vip:True\"\n",
        "    Current_amount: Today's amount\n",
        "    percentage_change: float number which represents change from yesterday\n",
        "    Example output: \"Users who are from australia and are VIP: $2805633 (Down 212.58%  from yesterday)\"\n",
        "    \"\"\"\n",
        "    categories = segment_name.split(\",\")\n",
        "    final_string = \"Users who \"\n",
        "    categories = [map_category(c) for c in categories]\n",
        "\n",
        "    final_string = final_string + \" and \".join(categories) + get_stats_string(current_amount,percentage_change)\n",
        "    return final_string\n",
        "\n",
        "print(humanReadableString(\"country:australia,is_vip:True\",2.805633e+06,-212.579900))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-SZlNFYJYZk",
        "outputId": "2dac99ab-fbb1-43a0-f7f8-3620de08317d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users who are from australia and are VIP: $2805633 (Down 212.58%  from yesterday)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driver Module"
      ],
      "metadata": {
        "id": "UCzw9ZQtKM6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def analyse_and_print_observations(df,metric,SEGMENT_CATEGORIES,CURRENT_COLUMN,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD):\n",
        "    \"\"\"\n",
        "    Driver function to trigger analysis on given metric and print results\n",
        "    Arguments:\n",
        "    metric: \"total\" or \"average\"\n",
        "    SEGMENT_CATEGORIES: \"column header on which segments to be generated\"\n",
        "    CURRENT_COLUMN: \"represents column header for absolute value to be printed\"\n",
        "    NUMERATOR_COLUMN: \"numerator column header which has delta change\"\n",
        "    DENOMINATOR_COLUMN: \"denominator column which holds value for last day\"\n",
        "    FILTER_THRESHOLD: \"threshold percentage for which we show observations\"\n",
        "    \"\"\"\n",
        "    print(\"analysing for %s metric\" % metric)\n",
        "    \n",
        "    # Getting Analysis on segment level and then on overall level\n",
        "    metric_analysis_df = get_analysis(df, metric, SEGMENT_CATEGORIES, [CURRENT_COLUMN], NUMERATOR_COLUMN,\n",
        "                                      DENOMINATOR_COLUMN)\n",
        "    overall_absolute_value, overall_absolute_change, overall_change_percentage = get_overallStats(df, CURRENT_COLUMN,NUMERATOR_COLUMN, DENOMINATOR_COLUMN,\n",
        "                                                                          metric)\n",
        "\n",
        "    ## Creatig comparision columns for filtering \n",
        "    metric_analysis_df[\"value_change_wrt_overall\"] = (metric_analysis_df[\n",
        "                                                          NUMERATOR_COLUMN] * 100) / overall_absolute_change\n",
        "    metric_analysis_df[\"value_change_wrt_overall\"] = metric_analysis_df[\"value_change_wrt_overall\"].abs()                                                      \n",
        "    metric_analysis_df[\"percentage_change_wrt_overall\"] = (metric_analysis_df[\n",
        "                                                               NUMERATOR_COLUMN_PERCENTAGE] - overall_change_percentage)\n",
        "    metric_analysis_df[\"percentage_change_wrt_overall\"] = metric_analysis_df[\"percentage_change_wrt_overall\"].abs()\n",
        "\n",
        "    # filtering based on FILTER_THRESHOLD\n",
        "    metric_analysis_df = metric_analysis_df[(metric_analysis_df['value_change_wrt_overall'] > FILTER_THRESHOLD) & (\n",
        "            metric_analysis_df['percentage_change_wrt_overall'] > FILTER_THRESHOLD)]\n",
        "\n",
        "    # getting results in Human readable string and printing them\n",
        "    final_df = metric_analysis_df\n",
        "    final_df['human_readable_observation'] = final_df.apply(\n",
        "        lambda x: humanReadableString(x['segment_name'], x[CURRENT_COLUMN], x[NUMERATOR_COLUMN_PERCENTAGE]), axis=1)\n",
        "\n",
        "    \n",
        "    if (overall_change_percentage >= 0):\n",
        "        print(metric.upper()+\" purchases %d (Up %.2f%% from yesterday)\" % (\n",
        "        overall_absolute_value, overall_change_percentage))\n",
        "    else:\n",
        "        print(metric.upper()+\" purchases %d (Down %.2f%% from yesterday)\" % (\n",
        "        overall_absolute_value, overall_change_percentage))\n",
        "    results = final_df['human_readable_observation'].tolist()\n",
        "\n",
        "    for result in results:\n",
        "        print(result)\n"
      ],
      "metadata": {
        "id": "RKTGudbEKL3l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Location of csv file\n",
        "    FILEPATH = \"comparative.ai_take_home_test.csv\"\n",
        "\n",
        "    # Configuration of parameters\n",
        "    FILTER_THRESHOLD = 2\n",
        "    SEGMENT_CATEGORIES = [\"country\", \"is_vip\"]\n",
        "    IGNORE_USER_TYPES = [\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]\n",
        "\n",
        "    # Detailed Configuration of parameters\n",
        "    use_parallel_processing = True\n",
        "    num_partitions = 12\n",
        "    CURRENT_COLUMN = 'purchased_amount_today'\n",
        "    NUMERATOR_COLUMN = 'amount_change'\n",
        "    DENOMINATOR_COLUMN = 'purchased_amount_yesterday'\n",
        "    NUMERATOR_COLUMN_PERCENTAGE = 'amount_change_percentage'\n",
        "    \n",
        "\n",
        "    df = getDf(FILEPATH)\n",
        "    print(\"Read CSV\")\n",
        "    # Creation of user_type column to represent the type of user in terms of:\n",
        "    # [\"regular_customer\",\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]\n",
        "    if use_parallel_processing == True:\n",
        "        partitionedDf = dd.from_pandas(df, npartitions=num_partitions)\n",
        "        df['user_type'] = partitionedDf.map_partitions(\n",
        "            lambda df: df.apply(lambda x: user_type(x[DENOMINATOR_COLUMN], x[CURRENT_COLUMN]),\n",
        "                                axis=1)).compute(scheduler='processes')\n",
        "    else:\n",
        "        df['user_type'] = df.apply(lambda x: user_type(x[DENOMINATOR_COLUMN], x[CURRENT_COLUMN]),\n",
        "                                   axis=1)\n",
        "\n",
        "    # excluding users in IGNORE_USER_TYPES\n",
        "    print(\"Ignoring Users: \"+str(IGNORE_USER_TYPES))\n",
        "    df = df[~df[\"user_type\"].isin(IGNORE_USER_TYPES)]\n",
        "\n",
        "\n",
        "    # Creating a change column which would be used throughout the code \n",
        "    # for calculating absolute change, absolute change percentage and other metrics\n",
        "    if use_parallel_processing:\n",
        "        partitionedDf = dd.from_pandas(df, npartitions=num_partitions)\n",
        "        df['amount_change'] = partitionedDf.map_partitions(\n",
        "            lambda df: df.apply(lambda x: amount_change(x[DENOMINATOR_COLUMN], x[CURRENT_COLUMN]),\n",
        "                                axis=1)).compute(scheduler='processes')\n",
        "    else:\n",
        "        df['amount_change'] = df.apply(\n",
        "            lambda x: amount_change(x[DENOMINATOR_COLUMN], x[CURRENT_COLUMN]), axis=1)\n",
        "\n",
        "    analyse_and_print_observations(df,\"total\",SEGMENT_CATEGORIES,CURRENT_COLUMN,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD)\n",
        "    print(\"\\n***************************************\\n\")\n",
        "    analyse_and_print_observations(df,\"average\",SEGMENT_CATEGORIES,CURRENT_COLUMN,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnh4KxclJaX6",
        "outputId": "0281da2e-9ca9-44e4-b11e-713590179b91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read CSV\n",
            "Ignoring Users: ['non_paying', 'abstained_yesterday', 'abstained_today']\n",
            "analysing for total metric\n",
            "TOTAL purchases 25533737 (Up 109.82% from yesterday)\n",
            "Users who are from australia: $2520279 (Up 90.98%  from yesterday)\n",
            "Users who are from australia and are not VIP: $1206322 (Up 99.23%  from yesterday)\n",
            "Users who are from australia and are VIP: $1313957 (Up 83.98%  from yesterday)\n",
            "Users who are from brazil: $2524028 (Up 126.72%  from yesterday)\n",
            "Users who are from brazil and are not VIP: $1231809 (Up 118.24%  from yesterday)\n",
            "Users who are from brazil and are VIP: $1292218 (Up 135.44%  from yesterday)\n",
            "Users who are from canada: $2711717 (Up 101.55%  from yesterday)\n",
            "Users who are from canada and are not VIP: $1019294 (Up 101.42%  from yesterday)\n",
            "Users who are from canada and are VIP: $1692423 (Up 101.62%  from yesterday)\n",
            "Users who are from korea: $2616028 (Up 106.09%  from yesterday)\n",
            "Users who are from korea and are not VIP: $1339733 (Up 105.79%  from yesterday)\n",
            "Users who are from korea and are VIP: $1276295 (Up 106.41%  from yesterday)\n",
            "Users who are from mexico: $2341896 (Up 102.29%  from yesterday)\n",
            "Users who are from mexico and are not VIP: $1100441 (Up 94.39%  from yesterday)\n",
            "Users who are from philipines and are not VIP: $1172272 (Up 107.16%  from yesterday)\n",
            "Users who are from russia: $2765589 (Up 118.20%  from yesterday)\n",
            "Users who are from russia and are not VIP: $1385857 (Up 118.11%  from yesterday)\n",
            "Users who are from russia and are VIP: $1379732 (Up 118.30%  from yesterday)\n",
            "Users who are from ukraine: $2428555 (Up 128.95%  from yesterday)\n",
            "Users who are from ukraine and are not VIP: $1285429 (Up 133.82%  from yesterday)\n",
            "Users who are from ukraine and are VIP: $1143125 (Up 123.71%  from yesterday)\n",
            "Users who are from usa: $2593638 (Up 105.30%  from yesterday)\n",
            "Users who are from usa and are not VIP: $1208789 (Up 112.01%  from yesterday)\n",
            "Users who are from usa and are VIP: $1384849 (Up 99.78%  from yesterday)\n",
            "Users who are from vietnam: $2757491 (Up 114.41%  from yesterday)\n",
            "Users who are from vietnam and are not VIP: $1419815 (Up 126.38%  from yesterday)\n",
            "Users who are from vietnam and are VIP: $1337675 (Up 103.01%  from yesterday)\n",
            "\n",
            "***************************************\n",
            "\n",
            "analysing for average metric\n",
            "AVERAGE purchases 7034 (Up 109.82% from yesterday)\n",
            "Users who are from australia: $7159 (Up 90.98%  from yesterday)\n",
            "Users who are from australia and are not VIP: $6972 (Up 99.23%  from yesterday)\n",
            "Users who are from australia and are VIP: $7340 (Up 83.98%  from yesterday)\n",
            "Users who are from brazil: $7011 (Up 126.72%  from yesterday)\n",
            "Users who are from brazil and are not VIP: $7288 (Up 118.24%  from yesterday)\n",
            "Users who are from brazil and are VIP: $6765 (Up 135.44%  from yesterday)\n",
            "Users who are from canada: $7270 (Up 101.55%  from yesterday)\n",
            "Users who are from canada and are not VIP: $6795 (Up 101.42%  from yesterday)\n",
            "Users who are from canada and are VIP: $7589 (Up 101.62%  from yesterday)\n",
            "Users who are from korea: $7108 (Up 106.09%  from yesterday)\n",
            "Users who are from korea and are not VIP: $6835 (Up 105.79%  from yesterday)\n",
            "Users who are from korea and are VIP: $7420 (Up 106.41%  from yesterday)\n",
            "Users who are from mexico: $6949 (Up 102.29%  from yesterday)\n",
            "Users who are from mexico and are not VIP: $6792 (Up 94.39%  from yesterday)\n",
            "Users who are from philipines and are not VIP: $6895 (Up 107.16%  from yesterday)\n",
            "Users who are from russia: $7019 (Up 118.20%  from yesterday)\n",
            "Users who are from russia and are not VIP: $7106 (Up 118.11%  from yesterday)\n",
            "Users who are from russia and are VIP: $6933 (Up 118.30%  from yesterday)\n",
            "Users who are from ukraine: $6708 (Up 128.95%  from yesterday)\n",
            "Users who are from ukraine and are not VIP: $6729 (Up 133.82%  from yesterday)\n",
            "Users who are from ukraine and are VIP: $6684 (Up 123.71%  from yesterday)\n",
            "Users who are from usa: $7086 (Up 105.30%  from yesterday)\n",
            "Users who are from usa and are not VIP: $6868 (Up 112.01%  from yesterday)\n",
            "Users who are from usa and are VIP: $7288 (Up 99.78%  from yesterday)\n",
            "Users who are from vietnam: $7275 (Up 114.41%  from yesterday)\n",
            "Users who are from vietnam and are not VIP: $7207 (Up 126.38%  from yesterday)\n",
            "Users who are from vietnam and are VIP: $7349 (Up 103.01%  from yesterday)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "Take Home Test Instructions:\n",
        "\n",
        "Product Requirements::\n",
        "- Technology stack: Python, Pandas and/or SQL\n",
        "- Dataset: comparative.ai take home test.csv\n",
        "\n",
        "Product Definition:\n",
        "Build an algorithm to look for user segments having significant metric changes today vs yesterday.\n",
        "\n",
        "Metrics:\n",
        "- Total purchased amount\n",
        "- Average purchased amount per paying user (exclude users who did not pay)User segments:\n",
        "Any combination of country and is_vip values.Examples:\n",
        "- Users from Canada\n",
        "- Users from Canada and are VIP\n",
        "- Users who are not VIP\n",
        "\n",
        "Significant metric change definition:\n",
        "\n",
        "\n",
        "\n",
        "Need to meet all of the following conditions:\n",
        "- Segment’s change absolute percentage is 2% greater than Overall’s change absolute percentage\n",
        "- Segment’s change absolute value is greater than 2% of Overall’s change absolute value\n",
        "\n",
        "Example output format:\n",
        "```\n",
        "  - Total purchased amount: $100 (up 10% from yesterday)\n",
        "  - Users from Canada: $50 (down 20% from yesterday)\n",
        "  - Users from Canada and are not VIP: $10 (up 12% from yesterday)\n",
        "  - Users who are VIP: $30 (down %10 from yesterday)\n",
        "  ...\n",
        "  - Average purchased amount per paying user: $3.4 (up %20 from yesterday)\n",
        "```\n",
        "...Bonus points:\n",
        "1. Group segments as much as possible. For example, instead of printing:\n",
        "- Users from Canada\n",
        "- Users who are VIP\n",
        "- Users from Canada and are not VIP\n",
        "- Users from Canada and are VIP\n",
        "\n",
        "We’d like to see:\n",
        "- Users from Canada\n",
        "- Users from Canada and are not VIP\n",
        "- Users from Canada and are VIP\n",
        "- Users who are VIP\n",
        "2. Parallelize your algorithm across multiple cores.Submission:\n",
        "\n",
        "\n",
        "Please send us the Github repository link or zip file with your code within 3 days. We will evaluate the code on:\n",
        "- Code Quality and Readibility\n",
        "- Python, Pandas and/or SQL best practices"
      ],
      "metadata": {
        "id": "bo8540wNLami"
      }
    }
  ]
}