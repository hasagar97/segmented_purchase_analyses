{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyse_purchases_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## how to use\n",
        "\n",
        "1. Unzip and Install requirements\n",
        "```\n",
        "dask==2022.4.1\n",
        "numpy==1.22.3\n",
        "pandas==1.4.2\n",
        "notebook==6.4.2\n",
        "```\n",
        "\n",
        "\n",
        "2. [option 1] Start Jupyter Notebook in the same folder\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "jupyter notebook\n",
        "```\n",
        "3. [option 2] run python file\n",
        "```bash\n",
        "python analyse_purchases.py\n",
        "```\n",
        "\n",
        "### Quick-Start\n",
        "\n",
        "- populate `FILEPATH` with the relative or absolute location of csv and run the Cells\n",
        "\n",
        "### Configuration of parameters\n",
        "\n",
        "    FILTER_THRESHOLD: Populate this variable to filter relavant observations, defaulted to 2\n",
        "    SEGMENT_CATEGORIES: Populate this list with the column headers of the csv file on which you want to create segments(refer to functionalities in next section for more details)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Functionalities and Design Choices\n",
        "- segement columns: Populate SEGMENT_CATEGORIES with the column names on which you want the segments to be created.\n",
        "  - for example if SEGMENT_CATEGORIES = [\"country\"], then you will see observations like \n",
        "    - users from canada\n",
        "    - users from korea\n",
        "  - for example if  SEGMENT_CATEGORIES = [\"country\"], then you would see observation like \n",
        "    - users who are from canada\n",
        "    - users who are from canada and are VIP\n",
        "    - users who are from canada and are not VIP\n",
        "- Segments are grouped, they will be ordered by the sequence of SEGMENT_CATEGORIES\n",
        "  - for example if it is set to  [\"country\", \"is_vip\"] then it will be first grouped by country and then VIP status\n",
        "    - For example all segments belonging to CANADA will occur together\n",
        "      - users who are from canada\n",
        "      - users who are from canada and are VIP\n",
        "      - users who are from canada and are not VIP\n",
        "<!-- - Ignoring Users: a function called user_type add a column called `user_type` which categorizes the users into 4 categories: [\"regular_customer\",\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]. A variable IGNORE_USER_TYPES is populated and all user types in this list would be excluded from the analysis. -->\n",
        "- `getDf()` Have created this function so that if in future if we need to read from some other source such as mysql, we can just edit this function\n",
        "- `metric` have tried to maintain this variable whenever possible so that in future in we have a new metric we can easily add more conditions\n",
        "\n",
        "## Assumptions\n",
        "- percentage calculation logic: The percentage is being calculated by comparing to yesterday\n",
        "$$\n",
        " PercentChange = \\frac{PurchaseToday - PurchaseYesterday}{PurchaseYesterday}\\times 100\n",
        "  $$\n",
        "- if the amount for a segment was 0 yesterday and non zero today then that is considered as 100% increase\n",
        "- if the amount for a segement was non zero yesterday and 0 today then that is considered as 100% drop\n",
        "- Ignore users on each day who did not purchase any amount. An user can be included in yesterday's analysis and not be included in today's analysis\n",
        "- User_ids are not repeated: if repeated we can first groupBy-Sum on user_id,country and is_vip and then start the whole process\n",
        "\n",
        "\n",
        "\n",
        "## Future steps\n",
        "\n",
        "- Reusability: add functions so that if business logic changes, the amount of changes we need to do is minimal\n",
        "- Parallelization: Very similar to apache spark we can use dask in an asynchronus manner, so that it computes only when results are needed. The current parallelization is close to none"
      ],
      "metadata": {
        "id": "VzfjckasVSxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'fsspec>=0.3.3'\n",
        "!pip install dask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVLpkMkuKdO6",
        "outputId": "65f6b33e-6dd1-4c7f-a91b-e795b1d89943"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec>=0.3.3 in /usr/local/lib/python3.7/dist-packages (2022.3.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CA5uf03iJJh_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd  # Dask Multiprocessing\n",
        "from itertools import combinations\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reader and Filter Module"
      ],
      "metadata": {
        "id": "mlzx9UJ6JhAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def getDf(filename):\n",
        "    \"\"\"\n",
        "    function to return data frame from csv,\n",
        "    can be modified to read from mysql\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(filename)\n",
        "    return df\n",
        "\n",
        "\n",
        "def user_type(yesterday, today):\n",
        "    \"\"\"\n",
        "    function to find out the types of users\n",
        "    \"\"\"\n",
        "    if (yesterday == 0 and today == 0):\n",
        "        return \"non_paying\"\n",
        "    if (yesterday == 0 and today != 0):\n",
        "        return \"abstained_yesterday\"\n",
        "    if (yesterday != 0 and today == 0):\n",
        "        return \"abstained_today\"\n",
        "    if (yesterday != 0 and today != 0):\n",
        "        return \"regular_user\"\n",
        "\n",
        "\n",
        "def amount_change(yesterday, today):\n",
        "    return today - yesterday\n"
      ],
      "metadata": {
        "id": "tX2r4MY-Je_K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stats Generation and Analysis Module\n"
      ],
      "metadata": {
        "id": "0SQCsyApJzlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_name(row, columns):\n",
        "    values = [column + \":\" + str(row[column]) for column in columns]\n",
        "    return ','.join(values)\n",
        "\n",
        "\n",
        "def getCombinations(columns):\n",
        "    n = len(columns)\n",
        "    res = [list(com) for sub in range(n) for com in combinations(columns, sub + 1)]\n",
        "    return res\n",
        "\n",
        "\n",
        "def getChangePercentage(today,yesterday):\n",
        "    if(today == yesterday): # handles if both values are 0\n",
        "        return 0\n",
        "    elif(yesterday == 0):\n",
        "        return 100\n",
        "    elif(math.isnan(today)):\n",
        "      return -100\n",
        "    elif(math.isnan(yesterday)):\n",
        "      return 100\n",
        "    else:\n",
        "        return (today-yesterday)*100/yesterday\n",
        "\n",
        "def get_analysis(df, metric, segment_columns, metric_column_change_percentage, numerator_column, denominator_column):\n",
        "    \"\"\"\n",
        "    Gets Segments on segment_columns and calculates stats(value and percentage) \n",
        "    on the given metric and returns an standard dataframe\n",
        "    \n",
        "    Arguments:\n",
        "    df: input data frame\n",
        "    metric: \"total\"/\"average\"\n",
        "    segment_columns: \"column header on which segments to be generated\"\n",
        "    numerator_column: numerator column which has today's value\n",
        "    denominator_column: denominator column which has today's value\n",
        "    \"\"\"\n",
        "\n",
        "    # get all posible combinations of given segment categories\n",
        "    all_segments = getCombinations(segment_columns)\n",
        "\n",
        "    combined_df = pd.DataFrame()\n",
        "    for segment in all_segments:\n",
        "        current_segment = df[df[numerator_column] > 0]\n",
        "        old_segment = df[df[denominator_column] > 0]\n",
        "\n",
        "        #  get metric for current and old column\n",
        "        if (metric == \"total\"):\n",
        "            current_segment = current_segment.groupby(segment)[numerator_column].sum().reset_index()\n",
        "            old_segment = old_segment.groupby(segment)[denominator_column].sum().reset_index()\n",
        "        elif (metric == \"average\"):\n",
        "            current_segment = current_segment.groupby(segment)[numerator_column].mean().reset_index()\n",
        "            old_segment = old_segment.groupby(segment)[denominator_column].mean().reset_index()\n",
        "\n",
        "        # joining on segment\n",
        "        segment_df = pd.merge(current_segment, old_segment, how=\"outer\", on=segment)\n",
        "        \n",
        "\n",
        "        # get percentage\n",
        "        segment_df[metric_column_change_percentage] = segment_df.apply(lambda x: getChangePercentage(x[numerator_column],x[denominator_column]), axis=1)\n",
        "        segment_df[\"segment_name\"] = segment_df.apply(lambda x: segment_name(x, segment), axis=1)\n",
        "\n",
        "        # After outer join if NaN value is present for today it means it's 100% drop\n",
        "        # NaN value for yesterday means it is 100 increase\n",
        "        segment_df[numerator_column] = segment_df[numerator_column].replace(np.nan, -100)\n",
        "        segment_df[denominator_column] = segment_df[denominator_column].replace(np.nan, 100)\n",
        "        # selecting columns to maintain standard format\n",
        "        segment_df = segment_df[['segment_name', numerator_column, metric_column_change_percentage]]\n",
        "        combined_df = pd.concat([combined_df,segment_df])\n",
        "\n",
        "    # sorting by segment_name to group segments together\n",
        "    combined_df = combined_df.sort_values(by=['segment_name']).reset_index(drop=True)\n",
        "    return combined_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_overallStats(df,metric,numerator_column, denominator_column):\n",
        "    \"\"\"\n",
        "    Returns overall absolute change, overall absolute change percentage\n",
        "    and overall_purchase today for the given metric without segmenting\n",
        "    \"\"\"\n",
        "    if(metric == \"total\"):\n",
        "        overall_purchase_yesterday = df[denominator_column].sum()\n",
        "        overall_purchase_today = df[numerator_column].sum()\n",
        "    elif(metric == \"average\"):\n",
        "        overall_purchase_yesterday = df[denominator_column].replace(0, np.nan).mean(skipna=True)\n",
        "        overall_purchase_today = df[numerator_column].replace(0, np.nan).mean(skipna=True)\n",
        "\n",
        "    if(math.isnan(overall_purchase_today)):\n",
        "        overall_purchase_today = 0\n",
        "    if(math.isnan(overall_purchase_yesterday)):\n",
        "        overall_purchase_yesterday=0\n",
        "\n",
        "    overall_absolute_change = overall_purchase_today-overall_purchase_yesterday\n",
        "    overall_change_percentage = getChangePercentage(overall_purchase_today,overall_purchase_yesterday)\n",
        "    return overall_purchase_today,overall_absolute_change, overall_change_percentage\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UEiKx2RDJQGT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human Readable String generation module"
      ],
      "metadata": {
        "id": "VgyuLG5sKEM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bq-WkkS0J9Ac"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_category(key_value):\n",
        "    \"\"\"\n",
        "    returns human readable segments string given segement_name in specific format\n",
        "    example: \"Users who are from australia and are VIP\"\n",
        "    \"\"\"\n",
        "    pair = key_value.split(\":\")\n",
        "    c = \"\"\n",
        "    if(pair[0] == \"country\"):\n",
        "        c = \"are from \"+pair[1]\n",
        "    else:\n",
        "        if(pair[1] == \"False\"):\n",
        "            c = \"are not VIP\"\n",
        "        else:\n",
        "            c = \"are VIP\"\n",
        "    return c\n",
        "\n",
        "def get_stats_string(amount,percentage):\n",
        "    \"\"\"\n",
        "    returns human readable stats String given current amount and percentage\n",
        "    example: \"$2805633 (Down 212.58%  from yesterday)\"\n",
        "    \"\"\"\n",
        "    string = ': $%d' % amount\n",
        "    if(percentage >= 0):\n",
        "        string = string + \" (Up %.2f%%  from yesterday)\"%percentage\n",
        "    else:\n",
        "        string = string + \" (Down %.2f%%  from yesterday)\"%abs(percentage)\n",
        "    return string\n",
        "\n",
        "def humanReadableString(segment_name,current_amount,percentage_change):\n",
        "    \"\"\"\n",
        "    returns Human readble string using:\n",
        "    segment_name: segment's name in given format \"country:australia,is_vip:True\"\n",
        "    Current_amount: Today's amount\n",
        "    percentage_change: float number which represents change from yesterday\n",
        "    Example output: \"Users who are from australia and are VIP: $2805633 (Down 212.58%  from yesterday)\"\n",
        "    \"\"\"\n",
        "    categories = segment_name.split(\",\")\n",
        "    final_string = \"Users who \"\n",
        "    categories = [map_category(c) for c in categories]\n",
        "\n",
        "    final_string = final_string + \" and \".join(categories) + get_stats_string(current_amount,percentage_change)\n",
        "    return final_string\n",
        "\n",
        "# print(humanReadableString(\"country:australia,is_vip:True\",2.805633e+06,0))\n"
      ],
      "metadata": {
        "id": "y-SZlNFYJYZk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driver Module"
      ],
      "metadata": {
        "id": "UCzw9ZQtKM6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyse_and_print_observations(df,metric,SEGMENT_CATEGORIES,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD):\n",
        "    \"\"\"\n",
        "    Driver function to trigger analysis on given metric and print results\n",
        "    Arguments:\n",
        "    metric: \"total\" or \"average\"\n",
        "    SEGMENT_CATEGORIES: \"column header on which segments to be generated\"\\\n",
        "    NUMERATOR_COLUMN: \"numerator column header which has today's purchase\"\n",
        "    DENOMINATOR_COLUMN: \"denominator column which holds value for last day\"\n",
        "    FILTER_THRESHOLD: \"threshold percentage for which we show observations\"\n",
        "    \"\"\"\n",
        "    \n",
        "    # Getting Analysis on segment level and then on overall level\n",
        "    print(\"analysing for %s metric\" % metric)\n",
        "    metric_analysis_df = get_analysis(df, metric, SEGMENT_CATEGORIES, NUMERATOR_COLUMN_PERCENTAGE, NUMERATOR_COLUMN,\n",
        "                                      DENOMINATOR_COLUMN)\n",
        "    overall_absolute_value, overall_absolute_change, overall_change_percentage = get_overallStats(df,metric,NUMERATOR_COLUMN, DENOMINATOR_COLUMN)\n",
        "\n",
        "    ## Creatig comparision columns for filtering \n",
        "    metric_analysis_df[\"value_change_wrt_overall\"] = (metric_analysis_df[\n",
        "                                                          NUMERATOR_COLUMN] * 100) / overall_absolute_change\n",
        "    metric_analysis_df[\"value_change_wrt_overall\"] = metric_analysis_df[\"value_change_wrt_overall\"].abs()                                                      \n",
        "    metric_analysis_df[\"percentage_change_wrt_overall\"] = (metric_analysis_df[\n",
        "                                                               NUMERATOR_COLUMN_PERCENTAGE] - overall_change_percentage)\n",
        "    metric_analysis_df[\"percentage_change_wrt_overall\"] = metric_analysis_df[\"percentage_change_wrt_overall\"].abs()\n",
        "\n",
        "    # filtering based on FILTER_THRESHOLD\n",
        "    metric_analysis_df = metric_analysis_df[(metric_analysis_df['value_change_wrt_overall'] > FILTER_THRESHOLD) & (\n",
        "            metric_analysis_df['percentage_change_wrt_overall'] > FILTER_THRESHOLD)]\n",
        "\n",
        "    # getting results in Human readable string and printing them\n",
        "    final_df = metric_analysis_df\n",
        "    final_df['human_readable_observation'] = final_df.apply(\n",
        "        lambda x: humanReadableString(x['segment_name'], x[NUMERATOR_COLUMN], x[NUMERATOR_COLUMN_PERCENTAGE]), axis=1)\n",
        "\n",
        "    \n",
        "    if (overall_change_percentage >= 0):\n",
        "        print(metric.upper()+\" purchases %d (Up %.2f%% from yesterday)\" % (\n",
        "        overall_absolute_value, overall_change_percentage))\n",
        "    else:\n",
        "        print(metric.upper()+\" purchases %d (Down %.2f%% from yesterday)\" % (\n",
        "        overall_absolute_value, overall_change_percentage))\n",
        "\n",
        "        \n",
        "    results = final_df['human_readable_observation'].tolist()\n",
        "\n",
        "    for result in results:\n",
        "        print(result)\n",
        "    return final_df\n",
        "\n"
      ],
      "metadata": {
        "id": "RKTGudbEKL3l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    # Location of csv file\n",
        "    FILEPATH = \"comparative.ai_take_home_test.csv\"\n",
        "\n",
        "    # Configuration of parameters\n",
        "    FILTER_THRESHOLD = 2\n",
        "    SEGMENT_CATEGORIES = [\"country\", \"is_vip\"]\n",
        "    IGNORE_USER_TYPES = [\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]\n",
        "\n",
        "    # Detailed Configuration of parameters\n",
        "    use_parallel_processing = True\n",
        "    num_partitions = 12\n",
        "    NUMERATOR_COLUMN = 'purchased_amount_today'\n",
        "    DENOMINATOR_COLUMN = 'purchased_amount_yesterday'\n",
        "    NUMERATOR_COLUMN_PERCENTAGE = 'amount_change_percentage'\n",
        "\n",
        "\n",
        "    df = getDf(FILEPATH)\n",
        "    print(\"Read CSV\")\n",
        "    # Creation of user_type column to represent the type of user in terms of:\n",
        "    # [\"regular_customer\",\"non_paying\",\"abstained_yesterday\",\"abstained_today\"]\n",
        "    if use_parallel_processing == True:\n",
        "        partitionedDf = dd.from_pandas(df, npartitions=num_partitions)\n",
        "        df['user_type'] = partitionedDf.map_partitions(\n",
        "            lambda df: df.apply(lambda x: user_type(x[DENOMINATOR_COLUMN], x[NUMERATOR_COLUMN]),\n",
        "                                axis=1)).compute(scheduler='processes')\n",
        "    else:\n",
        "        df['user_type'] = df.apply(lambda x: user_type(x[DENOMINATOR_COLUMN], x[NUMERATOR_COLUMN]),\n",
        "                                    axis=1)\n",
        "\n",
        "    results_df = analyse_and_print_observations(df,\"total\",SEGMENT_CATEGORIES,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD)\n",
        "    print(\"\\n***************************************\\n\")\n",
        "    results_df = analyse_and_print_observations(df,\"average\",SEGMENT_CATEGORIES,NUMERATOR_COLUMN,DENOMINATOR_COLUMN,NUMERATOR_COLUMN_PERCENTAGE,FILTER_THRESHOLD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnh4KxclJaX6",
        "outputId": "688498c7-6ead-440a-9264-49a323ff7390"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read CSV\n",
            "analysing for total metric\n",
            "TOTAL purchases 42316463 (Up 247.67% from yesterday)\n",
            "Users who are from australia: $4125434 (Up 212.58%  from yesterday)\n",
            "Users who are from australia and are not VIP: $2040772 (Up 236.97%  from yesterday)\n",
            "Users who are from australia and are VIP: $2084662 (Up 191.90%  from yesterday)\n",
            "Users who are from brazil: $4101230 (Up 268.30%  from yesterday)\n",
            "Users who are from brazil and are not VIP: $2021579 (Up 257.99%  from yesterday)\n",
            "Users who are from brazil and are VIP: $2079651 (Up 278.90%  from yesterday)\n",
            "Users who are from canada: $4163058 (Up 209.24%  from yesterday)\n",
            "Users who are from canada and are not VIP: $1702953 (Up 236.50%  from yesterday)\n",
            "Users who are from canada and are VIP: $2460104 (Up 192.83%  from yesterday)\n",
            "Users who are from korea: $4349214 (Up 242.63%  from yesterday)\n",
            "Users who are from korea and are not VIP: $2202163 (Up 238.26%  from yesterday)\n",
            "Users who are from mexico: $3998506 (Up 245.37%  from yesterday)\n",
            "Users who are from mexico and are not VIP: $1931571 (Up 241.20%  from yesterday)\n",
            "Users who are from philipines: $4099746 (Up 277.36%  from yesterday)\n",
            "Users who are from philipines and are not VIP: $2100735 (Up 271.10%  from yesterday)\n",
            "Users who are from philipines and are VIP: $1999011 (Up 284.16%  from yesterday)\n",
            "Users who are from russia: $4648602 (Up 266.73%  from yesterday)\n",
            "Users who are from russia and are not VIP: $2278338 (Up 258.58%  from yesterday)\n",
            "Users who are from russia and are VIP: $2370264 (Up 274.93%  from yesterday)\n",
            "Users who are from ukraine: $4062890 (Up 283.03%  from yesterday)\n",
            "Users who are from ukraine and are not VIP: $2096473 (Up 281.36%  from yesterday)\n",
            "Users who are from ukraine and are VIP: $1966417 (Up 284.83%  from yesterday)\n",
            "Users who are from usa: $4278562 (Up 238.67%  from yesterday)\n",
            "Users who are from usa and are not VIP: $2020566 (Up 254.39%  from yesterday)\n",
            "Users who are from usa and are VIP: $2257995 (Up 225.75%  from yesterday)\n",
            "Users who are from vietnam and are not VIP: $2293974 (Up 265.68%  from yesterday)\n",
            "Users who are from vietnam and are VIP: $2195240 (Up 232.92%  from yesterday)\n",
            "Users who are not VIP: $20689129 (Up 254.13%  from yesterday)\n",
            "Users who are VIP: $21627333 (Up 241.71%  from yesterday)\n",
            "\n",
            "***************************************\n",
            "\n",
            "analysing for average metric\n",
            "AVERAGE purchases 4476 (Up 33.89% from yesterday)\n",
            "Users who are from australia: $4474 (Up 19.68%  from yesterday)\n",
            "Users who are from australia and are not VIP: $4314 (Up 23.96%  from yesterday)\n",
            "Users who are from australia and are VIP: $4642 (Up 16.37%  from yesterday)\n",
            "Users who are from brazil: $4582 (Up 48.55%  from yesterday)\n",
            "Users who are from brazil and are not VIP: $4615 (Up 38.95%  from yesterday)\n",
            "Users who are from brazil and are VIP: $4550 (Up 58.36%  from yesterday)\n",
            "Users who are from canada: $4559 (Up 27.02%  from yesterday)\n",
            "Users who are from canada and are not VIP: $4143 (Up 23.63%  from yesterday)\n",
            "Users who are from canada and are VIP: $4900 (Up 30.66%  from yesterday)\n",
            "Users who are from korea: $4516 (Up 30.93%  from yesterday)\n",
            "Users who are from korea and are VIP: $4558 (Up 26.81%  from yesterday)\n",
            "Users who are from mexico: $4437 (Up 29.56%  from yesterday)\n",
            "Users who are from mexico and are not VIP: $4330 (Up 24.70%  from yesterday)\n",
            "Users who are from philipines: $4174 (Up 30.65%  from yesterday)\n",
            "Users who are from philipines and are not VIP: $4340 (Up 31.11%  from yesterday)\n",
            "Users who are from philipines and are VIP: $4014 (Up 30.37%  from yesterday)\n",
            "Users who are from russia: $4548 (Up 41.74%  from yesterday)\n",
            "Users who are from russia and are not VIP: $4612 (Up 41.54%  from yesterday)\n",
            "Users who are from russia and are VIP: $4489 (Up 42.02%  from yesterday)\n",
            "Users who are from ukraine: $4373 (Up 49.25%  from yesterday)\n",
            "Users who are from ukraine and are not VIP: $4489 (Up 55.97%  from yesterday)\n",
            "Users who are from ukraine and are VIP: $4256 (Up 42.44%  from yesterday)\n",
            "Users who are from usa and are not VIP: $4460 (Up 37.69%  from yesterday)\n",
            "Users who are from usa and are VIP: $4733 (Up 29.75%  from yesterday)\n",
            "Users who are from vietnam and are not VIP: $4506 (Up 42.25%  from yesterday)\n",
            "Users who are from vietnam and are VIP: $4516 (Up 26.04%  from yesterday)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vl_BQUoWbG0H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "Take Home Test Instructions:\n",
        "\n",
        "Product Requirements::\n",
        "- Technology stack: Python, Pandas and/or SQL\n",
        "- Dataset: comparative.ai take home test.csv\n",
        "\n",
        "Product Definition:\n",
        "Build an algorithm to look for user segments having significant metric changes today vs yesterday.\n",
        "\n",
        "Metrics:\n",
        "- Total purchased amount\n",
        "- Average purchased amount per paying user (exclude users who did not pay)User segments:\n",
        "Any combination of country and is_vip values.Examples:\n",
        "- Users from Canada\n",
        "- Users from Canada and are VIP\n",
        "- Users who are not VIP\n",
        "\n",
        "Significant metric change definition:\n",
        "\n",
        "\n",
        "\n",
        "Need to meet all of the following conditions:\n",
        "- Segment’s change absolute percentage is 2% greater than Overall’s change absolute percentage\n",
        "- Segment’s change absolute value is greater than 2% of Overall’s change absolute value\n",
        "\n",
        "Example output format:\n",
        "```\n",
        "  - Total purchased amount: $100 (up 10% from yesterday)\n",
        "  - Users from Canada: $50 (down 20% from yesterday)\n",
        "  - Users from Canada and are not VIP: $10 (up 12% from yesterday)\n",
        "  - Users who are VIP: $30 (down %10 from yesterday)\n",
        "  ...\n",
        "  - Average purchased amount per paying user: $3.4 (up %20 from yesterday)\n",
        "```\n",
        "...Bonus points:\n",
        "1. Group segments as much as possible. For example, instead of printing:\n",
        "- Users from Canada\n",
        "- Users who are VIP\n",
        "- Users from Canada and are not VIP\n",
        "- Users from Canada and are VIP\n",
        "\n",
        "We’d like to see:\n",
        "- Users from Canada\n",
        "- Users from Canada and are not VIP\n",
        "- Users from Canada and are VIP\n",
        "- Users who are VIP\n",
        "2. Parallelize your algorithm across multiple cores.Submission:\n",
        "\n",
        "\n",
        "Please send us the Github repository link or zip file with your code within 3 days. We will evaluate the code on:\n",
        "- Code Quality and Readibility\n",
        "- Python, Pandas and/or SQL best practices"
      ],
      "metadata": {
        "id": "bo8540wNLami"
      }
    }
  ]
}